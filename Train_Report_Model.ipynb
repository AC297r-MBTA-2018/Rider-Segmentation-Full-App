{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, Activation\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RIDER_LABEL_DICT = {\n",
    "    0: 'random riders',\n",
    "    1: 'weekend riders',\n",
    "    2: 'less flexible commuters with normal commute hours',\n",
    "    3: 'less flexible commuters with early commute hours',\n",
    "    4: 'more flexible commuters with normal commute hours',\n",
    "    5: 'more flexible commuters with early commute hours',\n",
    "    6: 'weekend riders who also ride over weekdays'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_samples(profile_filenames, sample_factor=500, noise_std=0.2):\n",
    "    hr_cols = ['hr_' + str(i) for i in range(1, 169)]\n",
    "    X_1D = np.zeros((1, 168))\n",
    "    y = np.zeros(1,)\n",
    "    for filename in profile_filenames:\n",
    "        df_profile = pd.read_csv(filename, index_col=0)\n",
    "        X_1D = np.vstack((X_1D, df_profile[hr_cols].values))\n",
    "        y = np.hstack((y, df_profile['manual_label'].values))\n",
    "    # drop the first (dummy) row\n",
    "    X_1D = X_1D[1:]\n",
    "    y = y[1:]\n",
    "    \n",
    "    # reshape the time matrix to be 7x24\n",
    "    X = X_1D.reshape((X_1D.shape[0], 7, 24))\n",
    "\n",
    "    # Upsample the temporal matrices by adding Gaussian noise\n",
    "    N = sample_factor * X.shape[0]\n",
    "    X_expand = np.zeros((N, 7, 24))\n",
    "    y_expand = np.zeros(N,)\n",
    "    for i in range(N):\n",
    "        X_expand[i] = X[int(i/sample_factor)] + np.random.normal(0, noise_std, (7, 24))\n",
    "        y_expand[i] = y[int(i/sample_factor)]\n",
    "\n",
    "    # Add a dimension to X_expand for 2D convolution\n",
    "    X_expand = np.expand_dims(X_expand, axis=-1)\n",
    "    return X_expand, y_expand\n",
    "\n",
    "def train_save_cnn(profile_filenames, batch_size=100, epochs=10, model_name='report_cnn.h5'):\n",
    "    X_expand, y_expand = generate_training_samples(profile_filenames)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_expand, y_expand, test_size=0.2, random_state=297)\n",
    "\n",
    "    # onehot-encode rider types\n",
    "    y_train_onehot = np.eye(len(RIDER_LABEL_DICT))[y_train.astype(int)]\n",
    "    y_test_onehot = np.eye(len(RIDER_LABEL_DICT))[y_test.astype(int)]\n",
    "\n",
    "    # model train\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), padding='same', input_shape=X_train.shape[1:]))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(len(RIDER_LABEL_DICT)))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "\n",
    "    # model fit\n",
    "    model.fit(X_train, y_train_onehot, batch_size=batch_size, epochs=epochs, validation_data=(X_test, y_test_onehot), shuffle=True)\n",
    "    \n",
    "    # model save\n",
    "    model.save(model_name)\n",
    "\n",
    "    scores = model.evaluate(X_test, y_test_onehot, verbose=1)\n",
    "    print('[Finished Fitting] loss:', scores[0])\n",
    "    print('[Finished Fitting] accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = []\n",
    "hier_s = ['non-hierarchical', 'hierarchical']\n",
    "algo_s = ['lda', 'kmeans']\n",
    "months_text = ['2016-Dec','2017-Jan','2017-Feb','2017-Mar','2017-Apr','2017-May','2017-Jun','2017-Jul','2017-Aug',\n",
    "              '2017-Sep','2017-Oct','2017-Nov']\n",
    "months = ['1612','1701','1702','1703','1704','1705','1706','1707','1708','1709','1710','1711']\n",
    "for hier in hier_s:\n",
    "    for algo in algo_s:\n",
    "        for month, month_text in zip(months, months_text):\n",
    "            files.append('data/cached_profiles/{}/{}_cluster_profiles_{}_1_0_{}.csv'.format(month_text,hier,month,algo))\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 129200 samples, validate on 32300 samples\n",
      "Epoch 1/10\n",
      "129200/129200 [==============================] - 32s 249us/step - loss: 0.1605 - acc: 0.9365 - val_loss: 0.0807 - val_acc: 0.9657\n",
      "Epoch 2/10\n",
      "129200/129200 [==============================] - 32s 244us/step - loss: 0.0676 - acc: 0.9713 - val_loss: 0.0540 - val_acc: 0.9773\n",
      "Epoch 3/10\n",
      "129200/129200 [==============================] - 32s 249us/step - loss: 0.0469 - acc: 0.9809 - val_loss: 0.0337 - val_acc: 0.9871\n",
      "Epoch 4/10\n",
      "129200/129200 [==============================] - 33s 254us/step - loss: 0.0345 - acc: 0.9863 - val_loss: 0.0406 - val_acc: 0.9846\n",
      "Epoch 5/10\n",
      "129200/129200 [==============================] - 30s 233us/step - loss: 0.0298 - acc: 0.9884 - val_loss: 0.0232 - val_acc: 0.9912\n",
      "Epoch 6/10\n",
      "129200/129200 [==============================] - 29s 225us/step - loss: 0.0255 - acc: 0.9901 - val_loss: 0.0339 - val_acc: 0.9872\n",
      "Epoch 7/10\n",
      "129200/129200 [==============================] - 28s 217us/step - loss: 0.0218 - acc: 0.9916 - val_loss: 0.0246 - val_acc: 0.9905\n",
      "Epoch 8/10\n",
      "129200/129200 [==============================] - 28s 219us/step - loss: 0.0193 - acc: 0.9927 - val_loss: 0.0462 - val_acc: 0.9843\n",
      "Epoch 9/10\n",
      "129200/129200 [==============================] - 31s 241us/step - loss: 0.0179 - acc: 0.9934 - val_loss: 0.0191 - val_acc: 0.9933\n",
      "Epoch 10/10\n",
      "129200/129200 [==============================] - 32s 246us/step - loss: 0.0157 - acc: 0.9942 - val_loss: 0.0193 - val_acc: 0.9933\n",
      "32300/32300 [==============================] - 3s 101us/step\n",
      "[Finished Fitting] loss: 0.019254854075378303\n",
      "[Finished Fitting] accuracy: 0.993250773993808\n"
     ]
    }
   ],
   "source": [
    "train_save_cnn(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
